{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Estimators\n",
    "How did we come up with the sample mean and sample variance as estimators of their population counterparts? Ok, it may seem obvious. We simply used sample moments to estimate population moments. But there are other ways we can think about coming up with estimators. Remember the goal is to come up with an estimator $\\hat{\\theta}_N$, which is a function of the data, that helps us understand the true underlying distribution of the population. Two common methods are least squares and maximum likelihood. We will consider an estimator for the population mean when we have an iid sample $X_1,...,X_N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method of (Matching) Moments\n",
    "Simply match population moments with sample moments. Since we know sample moments will converge in probability to population moments (by WLLN), this is the de facto method. For the mean, we construct our estimator $\\hat{\\theta}_N$ using the sample mean, i.e., \n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_N = \\bar{X}_N\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares\n",
    "Why not try minimizing the average distance between the estimator and data? For example, solving\n",
    "\n",
    "$$\n",
    "\\min_{\\hat{\\theta}}\\sum_{i=1}^N(X_i - \\hat{\\theta})^2.\n",
    "$$\n",
    "\n",
    "Taking FOCs w.r.t $\\hat{\\theta}$ we obtain\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^N-2(X_i - \\hat{\\theta}_N) = 0\n",
    "$$\n",
    "$$\n",
    "\\implies \\hat{\\theta}_N  = \\frac{1}{N}\\sum_{i=1}^NX_i = \\bar{X}_N, \n",
    "$$\n",
    "so that we obtain exactly the sample mean as our estimator!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood\n",
    "Suppose that each $X_i\\sim\\mathcal{N}(\\mu,\\sigma^2)$ where $\\mu$ and $\\sigma^2$ are just the population mean and variance. Let's write out the likelihood of observing our sample. Recall that the likelihood or probability of observing $X_i=x$ is written as the density $f(x)$. But we can use $X_i$ in place of $x$ so that $f(X_i)$ is now a random variable. But what we are actually interested in is the likelihood of the entire sample, i.e., $f(X_1,...,X_N)$, the joint density of the data. But since we assumed independence we have $f(X_1,...,X_N)=\\prod_if(X_i)$. Recalling the density of the normal distribution we can write the likelihood as\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(X_1,...,X_N;\\mu,\\sigma^2) \\equiv f(X_1,...,X_N)\n",
    "$$\n",
    "$$\n",
    "= \\prod_{i=1}^Nf(X_i) = \\prod_{i=1}^N\\frac{1}{\\sqrt{2\\pi}\\sigma}exp\\left(-\\frac{1}{2\\sigma^2}(X_i - \\mu)^2\\right)\n",
    "$$\n",
    "$$\n",
    "= \\left(\\frac{1}{\\sqrt{2\\pi}\\sigma}\\right)^Nexp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N(X_i - \\mu)^2\\right).\n",
    "$$\n",
    "\n",
    "Notice that maximizing this function is the same as maximizing the log of this function (a common trick) so that by taking logs we obtain\n",
    "\n",
    "$$\n",
    "N\\log\\frac{1}{\\sqrt{2\\pi}\\sigma} -\\frac{1}{2\\sigma^2}\\sum_{i=1}^N(X_i - \\mu)^2.\n",
    "$$\n",
    "\n",
    "Now we want to maximize the likelihood over $\\mu$ and $\\sigma^2$ to contruct our estimators. Taking FOC w.r.t. $\\mu$ we obtain\n",
    "\n",
    "$$\n",
    "-\\frac{1}{2\\sigma^2}\\sum_{i=1}^N2(X_i - \\hat{\\mu}_N) = 0\n",
    "$$\n",
    "\n",
    "so that, again, we obtain the sample mean as an estimator of the population mean $\\hat{\\mu}_N = \\bar{X}_N$!\n",
    "\n",
    "We are showing how to construct estimators in this manner because these type of estimators (Least Squares and Maximum Likelihood) will be used throughout the course and throughout your no doubt long career as econometricians."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
