{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditions for IV Estimation (No Controls)\n",
    "Let's consider the single endogenous regressor, single instrument IV case where $L=K=1$, i.e., that $X=(1,X_1)'$ and $Z=(1,Z_1)'$ are both $2\\times 1$ vectors. Let our structural model be\n",
    "$$\n",
    "Y = X'\\gamma + U\n",
    "$$\n",
    "$$\n",
    "= \\gamma_0 + \\gamma_1X_1 + U\n",
    "$$\n",
    "\n",
    "and assume that $E[U]=0$ but $E[X_1U]\\neq 0$, i.e., that $X_1$ is endogeneous. Let the standard regression conditions hold, i.e., that $E[XX']$ and $E[ZZ']$ are invertible (equivalently, no perfect collinearity in $Z$ or $X$). In order for the IV estimand $\\beta^{IV}$ to identify $\\gamma$ we require the following conditions to hold:\n",
    "\n",
    "## 1. Exogeneity \n",
    "\n",
    "$E[Z_1U] = 0$\n",
    "\n",
    "## 2. Relevance \n",
    "\n",
    "$Cov[X_1,Z_1]\\neq 0$\n",
    "\n",
    "## 3. Exclusion \n",
    "\n",
    "The structural equation $Y = X'\\gamma + U$ does not include $Z_1$ as a determinant of $Y$. This assumption is implicit when we write out the structural equation for $Y$ and don't include $Z_1$, but it is worth noting in practice to make sure that your structural model is specified correctly.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "Remember our plot of useful variation versus actual variation? Conditions (1) and (2) essentially guarantee that $Z_1$ provides useful variation for identifying the *ceterus parabus* effect of an increase in $X_1$ on $Y$. That is, it provides useful variation for the identification of $\\gamma_1$.\n",
    "\n",
    "If Condition (1), Exogeneity, doesn't hold then the same problem we had with $X_1$ shows up in $Z_1$. Namely, we can't untangle movements in $Z_1$ from movements in $U$.\n",
    "\n",
    "If Condition (2), Relevance, doesn't hold then even though movements in $Z_1$ may be independent of movements in $U$, they provide no useful information for movements in $X_1$. Thus, we can't link the exogenous variation in $Z_1$ to variation in $X_1$, and we therefore learn nothing about the *ceterus parabus* effect of changes in $X$ on changes in $Y$.\n",
    "\n",
    "## Testing the conditions\n",
    "\n",
    "Of the three conditions above, only Condition (2), Relevance, can be tested in the data. We usually test it by looking at the coefficient on the slope parameter from the first stage. Call this parameter $\\pi_1$. We can test the hypothesis that $H_0:\\pi_1=0$. If we reject, then the first stage is strong and we have evidence that we satisfy the Relevance condition. If we cannot reject, or the p-value is not too small, this is evidence that $Z_1$ is a *weak instrument*, and we should be worried that the variance of our IV estimate will be very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Supply and Demand for Labor\n",
    "\n",
    "Recall our labor supply and demand model for the farming industry. Labor supply and demand were written as\n",
    "$$\n",
    "g(H,V,U) = a_0 + a_1H + U + V\n",
    "$$\n",
    "$$\n",
    "f(U,Z) = b_0 + b_1U + b_2Q,\n",
    "$$\n",
    "and equating the two we could solve for the equilibrium level of hours worked:\n",
    "$$\n",
    "H = \\frac{b_0-a_0 + (b_1 - 1)U + b_2Q - V}{a_1}.\n",
    "$$\n",
    "Our structural equation of interest is the supply curve\n",
    "$$\n",
    "W = a_0 + a_1H + U + V,\n",
    "$$\n",
    "\n",
    "where we assume that $E[U]=E[V]=0$ and that soil quality $Q$ is unrelated to anything that shifts tastes for work, i.e, that $E[QU]=E[QV]=0$. Now let's see if we satisfy our assumptions for IV estimation. \n",
    "\n",
    "1. **Exogeneity**. This condition holds. Why? We assumed that $E[QU]=E[QV]=0$ so that $E[Q(U+V)]=0$. We have good reason to believe this to be true, as soil quality is likely unrelated to human capital $U$ and taste shifters $V$.\n",
    "\n",
    "2. **Relevance**. Since equilibrium hours worked are written as $H = \\frac{b_0-a_0 + (b_1 - 1)U + b_2Q - V}{a_1}$, they are a function of $Q$, so provided $b_2\\neq 0$, then $Cov[H,Q]\\neq 0$.\n",
    "\n",
    "3. **Exclusion**. We wrote out the supply curve so as not to be a function of soil quality $Q$, so this condition is satisfied.\n",
    "\n",
    "### Simulation\n",
    "\n",
    "Let's go ahead and simulate some data from this model. We will let $b_0=1$, $b_1=1$, $b_2=1$, $a_0=0.5$ and $a_1=1$, and let $U\\sim U[-0.75, 0.75]$, $V\\sim U[-0.25, 0.25]$ and $Q\\sim U[-0.25, 0.25]$. Because we know the precise way in which our data is generated in this simulation, we know that Conditions 1-3 hold, so that the IV estimator should converge to $a_1=1$.\n",
    "\n",
    "For ease of notation, we may sometimes write $Y=W$, $X=(1,X_1)'=(1,H)'$ and $Z=(1,Z_1)'=(1,Q)$. This will help us match our example up with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>W</th><th scope=col>H</th><th scope=col>Q</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.8985105  </td><td>0.5919283  </td><td>-0.11950464</td></tr>\n",
       "\t<tr><td>1.3762683  </td><td>0.4942684  </td><td>-0.12642235</td></tr>\n",
       "\t<tr><td>1.7758442  </td><td>0.7686322  </td><td> 0.18622874</td></tr>\n",
       "\t<tr><td>1.0338774  </td><td>0.4738535  </td><td> 0.11478720</td></tr>\n",
       "\t<tr><td>0.5237263  </td><td>0.1011106  </td><td>-0.17372953</td></tr>\n",
       "\t<tr><td>0.4748033  </td><td>0.7146198  </td><td> 0.10289106</td></tr>\n",
       "\t<tr><td>0.4924021  </td><td>0.1956776  </td><td>-0.17375258</td></tr>\n",
       "\t<tr><td>0.5570170  </td><td>0.8807128  </td><td> 0.24910121</td></tr>\n",
       "\t<tr><td>1.0115156  </td><td>0.3457241  </td><td> 0.06642625</td></tr>\n",
       "\t<tr><td>0.5443131  </td><td>0.3373904  </td><td>-0.00715636</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lll}\n",
       " W & H & Q\\\\\n",
       "\\hline\n",
       "\t 0.8985105   & 0.5919283   & -0.11950464\\\\\n",
       "\t 1.3762683   & 0.4942684   & -0.12642235\\\\\n",
       "\t 1.7758442   & 0.7686322   &  0.18622874\\\\\n",
       "\t 1.0338774   & 0.4738535   &  0.11478720\\\\\n",
       "\t 0.5237263   & 0.1011106   & -0.17372953\\\\\n",
       "\t 0.4748033   & 0.7146198   &  0.10289106\\\\\n",
       "\t 0.4924021   & 0.1956776   & -0.17375258\\\\\n",
       "\t 0.5570170   & 0.8807128   &  0.24910121\\\\\n",
       "\t 1.0115156   & 0.3457241   &  0.06642625\\\\\n",
       "\t 0.5443131   & 0.3373904   & -0.00715636\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "W | H | Q | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0.8985105   | 0.5919283   | -0.11950464 | \n",
       "| 1.3762683   | 0.4942684   | -0.12642235 | \n",
       "| 1.7758442   | 0.7686322   |  0.18622874 | \n",
       "| 1.0338774   | 0.4738535   |  0.11478720 | \n",
       "| 0.5237263   | 0.1011106   | -0.17372953 | \n",
       "| 0.4748033   | 0.7146198   |  0.10289106 | \n",
       "| 0.4924021   | 0.1956776   | -0.17375258 | \n",
       "| 0.5570170   | 0.8807128   |  0.24910121 | \n",
       "| 1.0115156   | 0.3457241   |  0.06642625 | \n",
       "| 0.5443131   | 0.3373904   | -0.00715636 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      W         H         Q          \n",
       " [1,] 0.8985105 0.5919283 -0.11950464\n",
       " [2,] 1.3762683 0.4942684 -0.12642235\n",
       " [3,] 1.7758442 0.7686322  0.18622874\n",
       " [4,] 1.0338774 0.4738535  0.11478720\n",
       " [5,] 0.5237263 0.1011106 -0.17372953\n",
       " [6,] 0.4748033 0.7146198  0.10289106\n",
       " [7,] 0.4924021 0.1956776 -0.17375258\n",
       " [8,] 0.5570170 0.8807128  0.24910121\n",
       " [9,] 1.0115156 0.3457241  0.06642625\n",
       "[10,] 0.5443131 0.3373904 -0.00715636"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(210)\n",
    "N = 1000\n",
    "b0 = 1\n",
    "b1 = 1\n",
    "b2 = 1\n",
    "a0 = 0.5\n",
    "a1 = 1\n",
    "\n",
    "# Simulating heterogeneity\n",
    "U = runif(N, -0.75, 0.75)\n",
    "V = runif(N, -0.25, 0.25)\n",
    "Q = runif(N, -0.25, 0.25)\n",
    "\n",
    "# Computing hours worked and wages\n",
    "H = (b0 - a0)/a1 - V/a1 + b2*Q/a1 + (b1 - 1)*U/a1\n",
    "W = b0 + b1*U + b2*Q\n",
    "\n",
    "data = cbind(W, H, Q)\n",
    "data[1:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = data[, 1]\n",
    "X = cbind(rep(1,N), data[,2])\n",
    "Z = cbind(rep(1,N), data[,3])\n",
    "\n",
    "L = dim(Z)[2] - 1 # number of instruments\n",
    "K = dim(X)[2] - 1 # number of regressors\n",
    "\n",
    "reg = function(Y, X){solve(t(X)%*%X)%*%t(X)%*%Y}\n",
    "iv = function(Y, X, Z){reg(Y, Z%*%reg(X, Z))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td> 1.00000e+00</td><td>0.5079352   </td></tr>\n",
       "\t<tr><td>-2.13371e-16</td><td>0.9341092   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       "\t  1.00000e+00 & 0.5079352   \\\\\n",
       "\t -2.13371e-16 & 0.9341092   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "|  1.00000e+00 | 0.5079352    | \n",
       "| -2.13371e-16 | 0.9341092    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]         [,2]     \n",
       "[1,]  1.00000e+00 0.5079352\n",
       "[2,] -2.13371e-16 0.9341092"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First stage\n",
    "pi = reg(X, Z)\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td> 0.02114218</td><td>-0.01318858</td></tr>\n",
       "\t<tr><td>-0.01318858</td><td> 0.97229594</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       "\t  0.02114218 & -0.01318858\\\\\n",
       "\t -0.01318858 &  0.97229594\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "|  0.02114218 | -0.01318858 | \n",
       "| -0.01318858 |  0.97229594 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]        [,2]       \n",
       "[1,]  0.02114218 -0.01318858\n",
       "[2,] -0.01318858  0.97229594"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ZZ_inv = solve(t(Z)%*%Z)\n",
    "Uf.hat = X[,2] - Z%*%pi[,2]\n",
    "pi1 = pi[,2]\n",
    "ZU = sweep(Z, MARGIN=1, Uf.hat, `*`)\n",
    "ZUUZ = t(ZU)%*%ZU\n",
    "Vf = N*ZZ_inv%*%ZUUZ%*%ZZ_inv # First stage estimate of variance\n",
    "Vf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "29.9570075546033"
      ],
      "text/latex": [
       "29.9570075546033"
      ],
      "text/markdown": [
       "29.9570075546033"
      ],
      "text/plain": [
       "[1] 29.95701"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.stat.f = pi[2,2]/sqrt(Vf[2,2]/N)\n",
    "t.stat.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p.val.f = 2*(1 - pnorm(abs(t.stat.f)))\n",
    "p.val.f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see this first stage result by doing the regression using the LM command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = H ~ Q, data = data.frame(data))\n",
       "\n",
       "Residuals:\n",
       "      Min        1Q    Median        3Q       Max \n",
       "-0.261399 -0.121400 -0.000996  0.133237  0.251718 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 0.507935   0.004598  110.48   <2e-16 ***\n",
       "Q           0.934109   0.031536   29.62   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.1449 on 998 degrees of freedom\n",
       "Multiple R-squared:  0.4678,\tAdjusted R-squared:  0.4673 \n",
       "F-statistic: 877.4 on 1 and 998 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit.f = lm(H ~ Q, data=data.frame(data))\n",
    "summary(fit.f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that it appears that the first stage is quite strong. The slight differences in the t-stats come from the fact that R assumes homoskedasticity by default in the `lm` command and it also makes degrees of freedom corrections. But these changes have minor effects as our t-stats are rather close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.5574834</td></tr>\n",
       "\t<tr><td>0.8958827</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.5574834\\\\\n",
       "\t 0.8958827\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.5574834 | \n",
       "| 0.8958827 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     \n",
       "[1,] 0.5574834\n",
       "[2,] 0.8958827"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b.iv = reg(Y, Z%*%pi)\n",
    "b.iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.5574834</td></tr>\n",
       "\t<tr><td>0.8958827</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.5574834\\\\\n",
       "\t 0.8958827\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.5574834 | \n",
       "| 0.8958827 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     \n",
       "[1,] 0.5574834\n",
       "[2,] 0.8958827"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b.iv = iv(Y, X, Z)\n",
    "b.iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we see we are quite close to the truth. If we had done OLS..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.7977931</td></tr>\n",
       "\t<tr><td>0.4324498</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.7977931\\\\\n",
       "\t 0.4324498\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.7977931 | \n",
       "| 0.4324498 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     \n",
       "[1,] 0.7977931\n",
       "[2,] 0.4324498"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b.ols = reg(Y, X)\n",
    "b.ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we would have been way off the truth. What about t-statistics and pvalues for second stage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td> 3.151625</td><td>-5.702071</td></tr>\n",
       "\t<tr><td>-5.702071</td><td>11.011021</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       "\t  3.151625 & -5.702071\\\\\n",
       "\t -5.702071 & 11.011021\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "|  3.151625 | -5.702071 | \n",
       "| -5.702071 | 11.011021 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]      [,2]     \n",
       "[1,]  3.151625 -5.702071\n",
       "[2,] -5.702071 11.011021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "piZZpi_inv = solve(t(pi)%*%t(Z)%*%Z%*%pi)\n",
    "U.hat = Y - X%*%reg(Y, Z%*%pi)\n",
    "ZU = sweep(Z, MARGIN=1, U.hat, `*`)\n",
    "piZUUZpi = t(pi)%*%t(ZU)%*%ZU%*%pi\n",
    "V = N*piZZpi_inv%*%piZUUZpi%*%piZZpi_inv # Second stage estimate of variance\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "8.53763091525806"
      ],
      "text/latex": [
       "8.53763091525806"
      ],
      "text/markdown": [
       "8.53763091525806"
      ],
      "text/plain": [
       "[1] 8.537631"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.stat = b.iv[2]/sqrt(V[2,2]/N)\n",
    "t.stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p.val = 2*(1 - pnorm(abs(t.stat)))\n",
    "p.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also have done this using the IV command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: car\n",
      "Loading required package: lmtest\n",
      "Loading required package: zoo\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "Loading required package: sandwich\n",
      "Loading required package: survival\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "ivreg(formula = W ~ H | Q, data = data.frame(data))\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-0.9267 -0.3722  0.0170  0.3769  0.9079 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.55748    0.05572  10.005   <2e-16 ***\n",
       "H            0.89588    0.10395   8.618   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.4463 on 998 degrees of freedom\n",
       "Multiple R-Squared: -0.005532,\tAdjusted R-squared: -0.006539 \n",
       "Wald test: 74.27 on 1 and 998 DF,  p-value: < 2.2e-16 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(AER)\n",
    "fit = ivreg(W ~ H|Q, data=data.frame(data))\n",
    "summary(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so that again, the t-statistic associated with `H` is close but not exact to what we computed above, based on differences how `ivreg` treats either homoskedasticity or degrees of freedom. But we see it largely doesn't matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV Conditions (with Controls)\n",
    "If we recall from class, for a general model $Y=\\gamma_1 + \\gamma_1X_1 + \\gamma_2X_2 + \\epsilon$, where $\\gamma_2$ may be 0, if we have an instrument $Z_1$, the IV estimand will identify $\\gamma_1$ if the following conditions hold. Let $\\tilde{Z}_1=Z_1 - BLP(X_1|X_2)$.\n",
    "\n",
    "## Exogeneity\n",
    "$Cov[\\tilde{Z}_1, \\epsilon]=0$\n",
    "\n",
    "## Relevance\n",
    "$Cov[\\tilde{Z}_1,X_1]\\neq 0$\n",
    "\n",
    "## Exclusion\n",
    "$Z_1$ is not in the structural model for $Y$.\n",
    "\n",
    "### Discussion\n",
    "So regardless of whether $X_2$ is in the structural model $\\gamma_2\\neq 0$ or not $\\gamma_2=0$, these conditions are the same. So a lot of times even if we think $\\gamma_2=0$, we may still include $X_2$ in our analysis if we think it can help isolate the exogenous variation in $Z_1$ to determine the effect of $X_1$ on $Y$.\n",
    "\n",
    "### Example: Labor Supply and Demand with Controls\n",
    "Now consider the labor supply and demand in the farming industry augmented with two additional variables $C$, for number of children, and $P$, for allergen or pollen content in the air at the farm:\n",
    "$$\n",
    "g(H,C,P,V,U) = a_0 + a_1H + a_2C + a_3P + V + U\n",
    "$$\n",
    "$$\n",
    "f(U,Q) = b_0 + b_1Q + U.\n",
    "$$\n",
    "Let us consider an IV scenario where $X=(1,H,C,P)'$ and $Z=(1,Q,C,P)'$. That is, we are proposing using $Q$ as an instrument for $H$ and using $C$ and $P$ as controls. Suppose further that the pollen content is directly related to soil quality, so that $Q = c_0 + c_1P + \\epsilon$. Assume some shifts in soil quality are directly connected with pollen content and therefore may be endogenous, but some shifts (due to $\\epsilon$) are completely exogenous.\n",
    "\n",
    "1. **Exogeneity**. We need that $Cov[\\tilde{Q},V+U]=0$ where $\\tilde{Q}=Q - BLP(Q|C,P)$. This should hold since after controlling for $P$, shifts in soil quality are assumed to be exogenous. Notice that if we don't control for $P$, then $Q$ would not be exogenous (we'll see the implications of not using $P$ as a control below). Why? Because omitting $P$ from the analysis, $P$ goes into the error, it determines $H$ and it is correlated with $Q$.\n",
    "2. **Relevance**. We need that $Cov[\\tilde{Q},H]\\neq 0$. This is clearly true by our assumptions, since even after controlling for $P$ and $C$ ($C$ is unrelated to $Q$), $Q$ is still correlated with $H$ through $\\epsilon$.\n",
    "3. **Exclusion**. By assumption of our model, $Q$ does not directly affect supply.\n",
    "\n",
    "### Simulation\n",
    "\n",
    "Let's go ahead again and simulate the data from this model. Solving for equilibrium hours worked we have\n",
    "$$\n",
    "H = \\frac{b_0 + b_1Q - a_0 - a_2C - a_3P - V}{a_1}.\n",
    "$$\n",
    "For our simulation, let $P$ be distributed $U[0,1]$ and $U$ and $V$ distributed $U[-0.5,0.5]$. Construct $C$ as $0.4V + 0.4S$ where $S$ is some variable that captures the cost of having children with distribution $U[0,1]$. Furthermore, let $b_0=b_1=1$ and $a_0=0$, $a_1=1$, and $a_2=a_3=0.25$. Assume $c_0=0.5$, $c_1=1$ and $\\epsilon\\sim[-0.5, 0.5]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>W</th><th scope=col>H</th><th scope=col>C</th><th scope=col>P</th><th scope=col>Q</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.6940386 </td><td>1.278966  </td><td>0.3522792 </td><td>0.0346164 </td><td>0.08033519</td></tr>\n",
       "\t<tr><td>2.0368684 </td><td>1.594477  </td><td>0.4668449 </td><td>0.8765384 </td><td>0.91456902</td></tr>\n",
       "\t<tr><td>2.0137378 </td><td>1.532908  </td><td>0.2084239 </td><td>0.7347251 </td><td>0.90446308</td></tr>\n",
       "\t<tr><td>1.8996361 </td><td>1.093959  </td><td>0.2705243 </td><td>0.6218362 </td><td>0.77625664</td></tr>\n",
       "\t<tr><td>2.3171924 </td><td>2.050227  </td><td>0.2113488 </td><td>0.6978030 </td><td>0.95627699</td></tr>\n",
       "\t<tr><td>2.5822114 </td><td>2.443002  </td><td>0.2635888 </td><td>0.5783307 </td><td>1.44190076</td></tr>\n",
       "\t<tr><td>1.6684968 </td><td>2.043967  </td><td>0.3563914 </td><td>0.5560342 </td><td>1.15900108</td></tr>\n",
       "\t<tr><td>1.4235288 </td><td>1.894837  </td><td>0.3287923 </td><td>0.5496697 </td><td>0.69097834</td></tr>\n",
       "\t<tr><td>2.2048536 </td><td>1.950013  </td><td>0.2644586 </td><td>0.9274793 </td><td>1.03876980</td></tr>\n",
       "\t<tr><td>1.4659642 </td><td>1.331461  </td><td>0.3221735 </td><td>0.2743850 </td><td>0.45171305</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       " W & H & C & P & Q\\\\\n",
       "\\hline\n",
       "\t 0.6940386  & 1.278966   & 0.3522792  & 0.0346164  & 0.08033519\\\\\n",
       "\t 2.0368684  & 1.594477   & 0.4668449  & 0.8765384  & 0.91456902\\\\\n",
       "\t 2.0137378  & 1.532908   & 0.2084239  & 0.7347251  & 0.90446308\\\\\n",
       "\t 1.8996361  & 1.093959   & 0.2705243  & 0.6218362  & 0.77625664\\\\\n",
       "\t 2.3171924  & 2.050227   & 0.2113488  & 0.6978030  & 0.95627699\\\\\n",
       "\t 2.5822114  & 2.443002   & 0.2635888  & 0.5783307  & 1.44190076\\\\\n",
       "\t 1.6684968  & 2.043967   & 0.3563914  & 0.5560342  & 1.15900108\\\\\n",
       "\t 1.4235288  & 1.894837   & 0.3287923  & 0.5496697  & 0.69097834\\\\\n",
       "\t 2.2048536  & 1.950013   & 0.2644586  & 0.9274793  & 1.03876980\\\\\n",
       "\t 1.4659642  & 1.331461   & 0.3221735  & 0.2743850  & 0.45171305\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "W | H | C | P | Q | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0.6940386  | 1.278966   | 0.3522792  | 0.0346164  | 0.08033519 | \n",
       "| 2.0368684  | 1.594477   | 0.4668449  | 0.8765384  | 0.91456902 | \n",
       "| 2.0137378  | 1.532908   | 0.2084239  | 0.7347251  | 0.90446308 | \n",
       "| 1.8996361  | 1.093959   | 0.2705243  | 0.6218362  | 0.77625664 | \n",
       "| 2.3171924  | 2.050227   | 0.2113488  | 0.6978030  | 0.95627699 | \n",
       "| 2.5822114  | 2.443002   | 0.2635888  | 0.5783307  | 1.44190076 | \n",
       "| 1.6684968  | 2.043967   | 0.3563914  | 0.5560342  | 1.15900108 | \n",
       "| 1.4235288  | 1.894837   | 0.3287923  | 0.5496697  | 0.69097834 | \n",
       "| 2.2048536  | 1.950013   | 0.2644586  | 0.9274793  | 1.03876980 | \n",
       "| 1.4659642  | 1.331461   | 0.3221735  | 0.2743850  | 0.45171305 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      W         H        C         P         Q         \n",
       " [1,] 0.6940386 1.278966 0.3522792 0.0346164 0.08033519\n",
       " [2,] 2.0368684 1.594477 0.4668449 0.8765384 0.91456902\n",
       " [3,] 2.0137378 1.532908 0.2084239 0.7347251 0.90446308\n",
       " [4,] 1.8996361 1.093959 0.2705243 0.6218362 0.77625664\n",
       " [5,] 2.3171924 2.050227 0.2113488 0.6978030 0.95627699\n",
       " [6,] 2.5822114 2.443002 0.2635888 0.5783307 1.44190076\n",
       " [7,] 1.6684968 2.043967 0.3563914 0.5560342 1.15900108\n",
       " [8,] 1.4235288 1.894837 0.3287923 0.5496697 0.69097834\n",
       " [9,] 2.2048536 1.950013 0.2644586 0.9274793 1.03876980\n",
       "[10,] 1.4659642 1.331461 0.3221735 0.2743850 0.45171305"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1234)\n",
    "N = 10000\n",
    "b0 = 1\n",
    "b1 = 1\n",
    "a0 = 0\n",
    "a1 = 1\n",
    "a2 = 0.25\n",
    "a3 = 0.25\n",
    "c0 = 0.5\n",
    "c1 = 1\n",
    "\n",
    "# Simulating heterogeneity\n",
    "U = runif(N, -0.5, 0.5)\n",
    "V = runif(N, -0.5, 0.5)\n",
    "P = runif(N, 0, 1)\n",
    "S = runif(N, 0, 1)\n",
    "e = runif(N, -0.5, 0.5)\n",
    "\n",
    "C = 0.4*V + 0.5*S\n",
    "Q = c0 + c1*P + e\n",
    "\n",
    "# Computing hours worked and wages\n",
    "H = (b0 + b1*Q - a0 - a2*C - a3*P - V)/a1\n",
    "W = b0 + b1*Q + U\n",
    "\n",
    "data = cbind(W, H, C, P, Q)\n",
    "data[1:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = data[, 1]\n",
    "X = cbind(rep(1,N), data[, c(2, 3, 4)])\n",
    "Z = cbind(rep(1,N), data[, c(5, 3, 4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = H ~ Q + C + P, data = data.frame(data))\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-0.53947 -0.16125 -0.00216  0.16038  0.54702 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  1.234520   0.006575  187.75   <2e-16 ***\n",
       "Q            0.996574   0.007745  128.67   <2e-16 ***\n",
       "C           -1.211266   0.011982 -101.09   <2e-16 ***\n",
       "P           -0.244328   0.011062  -22.09   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.2236 on 9996 degrees of freedom\n",
       "Multiple R-squared:  0.7847,\tAdjusted R-squared:  0.7846 \n",
       "F-statistic: 1.214e+04 on 3 and 9996 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit.f = lm(H ~ Q + C + P, data=data.frame(data))\n",
    "summary(fit.f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value on $Q$ is really small, so we believe we have a strong instrument that satisfies relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row></th><td>-0.257661</td></tr>\n",
       "\t<tr><th scope=row>H</th><td> 1.012427</td></tr>\n",
       "\t<tr><th scope=row>C</th><td> 1.223791</td></tr>\n",
       "\t<tr><th scope=row>P</th><td> 0.246857</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "\t & -0.257661\\\\\n",
       "\tH &  1.012427\\\\\n",
       "\tC &  1.223791\\\\\n",
       "\tP &  0.246857\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "|  | -0.257661 | \n",
       "| H |  1.012427 | \n",
       "| C |  1.223791 | \n",
       "| P |  0.246857 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [,1]     \n",
       "  -0.257661\n",
       "H  1.012427\n",
       "C  1.223791\n",
       "P  0.246857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b.iv = iv(Y, X, Z)\n",
    "b.iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our sample is very large so these estimates are really close to $\\beta^{IV}$. We see that the coefficient on $H$ is very close to 1, so IV does a nice job at estimating $a_1=1$. We also see that the coefficient on $P$ is $0.25$, so we also do a great job of estimating $a_3=0.25$. But what happened to $a_2$? Because $C$ has an endogenous component (it is correlated with tastes for work $V$) we cannot identify $a_2$ with $\\beta^{IV}_2$.\n",
    "\n",
    "Thus, we see that the model is partially identified and that we were able to identify our object of interest, $a_1$, without identifying all of the vector of supply parameters $a=(a_0,a_1,a_2,a_3)'$.\n",
    "\n",
    "We can confirm our result using the `ivreg` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "ivreg(formula = W ~ H + C + P | Q + C + P, data = data.frame(data))\n",
       "\n",
       "Residuals:\n",
       "      Min        1Q    Median        3Q       Max \n",
       "-1.007260 -0.272592  0.002755  0.269767  0.968761 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -0.25766    0.02374  -10.85   <2e-16 ***\n",
       "H            1.01243    0.01280   79.10   <2e-16 ***\n",
       "C            1.22379    0.02503   48.90   <2e-16 ***\n",
       "P            0.24686    0.01614   15.30   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.3683 on 9996 degrees of freedom\n",
       "Multiple R-Squared: 0.469,\tAdjusted R-squared: 0.4689 \n",
       "Wald test:  4250 on 3 and 9996 DF,  p-value: < 2.2e-16 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = ivreg(W ~ H + C + P|Q + C + P, data=data.frame(data))\n",
    "summary(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we forgot to control for $P$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "ivreg(formula = W ~ H + C | Q + C, data = data.frame(data))\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-1.15453 -0.28419  0.00215  0.28250  1.11728 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -0.43116    0.02389  -18.05   <2e-16 ***\n",
       "H            1.15352    0.01090  105.83   <2e-16 ***\n",
       "C            1.39483    0.02476   56.34   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.3929 on 9997 degrees of freedom\n",
       "Multiple R-Squared: 0.3955,\tAdjusted R-squared: 0.3954 \n",
       "Wald test:  5600 on 2 and 9997 DF,  p-value: < 2.2e-16 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = ivreg(W ~ H + C|Q + C, data=data.frame(data))\n",
    "summary(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we now have bias in our estimate of $a_1$ (remember we use a very large sample). This is because $Q$ is only exogenous after controlling for $P$. Thus, we needed to include the control in order to identify $a_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Returns to Schooling\n",
    "Let's do the example in class where we use a measure of distance to college as an instrument for schooling. Our measure is the number of colleges per square foot in each state in year 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = paste(\"https://raw.githubusercontent.com/jtorcasso/teaching/\",\n",
    "            \"master/econ210_fall2017/data/project/psid_2011.csv\", sep=\"\")\n",
    "df = read.csv(url)\n",
    "df$wage =  ifelse(df$inc_labor==0 | df$hours==0, NaN, df$inc_labor/df$hours)\n",
    "df$logwage = log(df$wage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge the college data to the PSID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url2 = paste(\"https://raw.githubusercontent.com/jtorcasso/teaching/\",\n",
    "            \"master/econ210_fall2017/data/project/col_info.csv\", sep=\"\")\n",
    "col.info = read.csv(url2)\n",
    "df = merge(df, col.info[,c(\"psid_id\", \"edu_dens\", \"count\")], by.x=\"birthstate\", by.y=\"psid_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "582"
      ],
      "text/latex": [
       "582"
      ],
      "text/markdown": [
       "582"
      ],
      "text/plain": [
       "[1] 582"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = c(\"edu\", \"edu_dens\", \"logwage\", \"birthyear\", \"black\", \"m_edu\", \"age\", \"workexp\")\n",
    "df.m = na.omit(df[df$male==1 & df$birthyear >= 1970 & df$birthyear <= 1985, cols])\n",
    "N = dim(df.m)[1]\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try it without any controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Estimate</dt>\n",
       "\t\t<dd>0.544092418269825</dd>\n",
       "\t<dt>Std. Error</dt>\n",
       "\t\t<dd>0.721234381461467</dd>\n",
       "\t<dt>t value</dt>\n",
       "\t\t<dd>0.754390572960912</dd>\n",
       "\t<dt>Pr(&gt;|t|)</dt>\n",
       "\t\t<dd>0.450920905929682</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Estimate] 0.544092418269825\n",
       "\\item[Std. Error] 0.721234381461467\n",
       "\\item[t value] 0.754390572960912\n",
       "\\item[Pr(>\\textbackslash{}textbar\\{\\}t\\textbackslash{}textbar\\{\\})] 0.450920905929682\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Estimate\n",
       ":   0.544092418269825Std. Error\n",
       ":   0.721234381461467t value\n",
       ":   0.754390572960912Pr(&amp;gt;|t|)\n",
       ":   0.450920905929682\n",
       "\n"
      ],
      "text/plain": [
       "  Estimate Std. Error    t value   Pr(>|t|) \n",
       " 0.5440924  0.7212344  0.7543906  0.4509209 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = ivreg(logwage ~ edu|edu_dens, data=df.m)\n",
    "summary(fit)$coef[2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woahh, this is a huge estimate. Let's check first stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = edu ~ edu_dens, data = df.m)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.3573 -2.2926 -0.2926  1.7056  2.7175 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  14.2762     0.1166  122.44   <2e-16 ***\n",
       "edu_dens      8.6054    11.6343    0.74     0.46    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 2.055 on 580 degrees of freedom\n",
       "Multiple R-squared:  0.0009424,\tAdjusted R-squared:  -0.0007801 \n",
       "F-statistic: 0.5471 on 1 and 580 DF,  p-value: 0.4598\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit.f = lm(edu ~ edu_dens, data=df.m)\n",
    "summary(fit.f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh, looks like a weak instrument. But let's go ahead and try everything but adding controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Estimate</dt>\n",
       "\t\t<dd>5.68337845632622</dd>\n",
       "\t<dt>Std. Error</dt>\n",
       "\t\t<dd>76.0716885236053</dd>\n",
       "\t<dt>t value</dt>\n",
       "\t\t<dd>0.0747108229964246</dd>\n",
       "\t<dt>Pr(&gt;|t|)</dt>\n",
       "\t\t<dd>0.940471381159231</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Estimate] 5.68337845632622\n",
       "\\item[Std. Error] 76.0716885236053\n",
       "\\item[t value] 0.0747108229964246\n",
       "\\item[Pr(>\\textbackslash{}textbar\\{\\}t\\textbackslash{}textbar\\{\\})] 0.940471381159231\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Estimate\n",
       ":   5.68337845632622Std. Error\n",
       ":   76.0716885236053t value\n",
       ":   0.0747108229964246Pr(&amp;gt;|t|)\n",
       ":   0.940471381159231\n",
       "\n"
      ],
      "text/plain": [
       "   Estimate  Std. Error     t value    Pr(>|t|) \n",
       " 5.68337846 76.07168852  0.07471082  0.94047138 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = ivreg(logwage ~ edu + factor(birthyear) + m_edu + black + age|\n",
    "            edu_dens + factor(birthyear) + m_edu + black + age, data=df.m)\n",
    "summary(fit)$coef[2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "ivreg(formula = edu ~ edu_dens + factor(birthyear) + m_edu + \n",
       "    black + age, data = df.m)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.9283 -1.4903  0.2455  1.3548  6.6724 \n",
       "\n",
       "Coefficients:\n",
       "                      Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)            7.13419    6.25758   1.140  0.25474    \n",
       "edu_dens               0.78064   10.62761   0.073  0.94147    \n",
       "factor(birthyear)1971 -1.60601    0.53344  -3.011  0.00272 ** \n",
       "factor(birthyear)1972 -1.10192    0.58237  -1.892  0.05899 .  \n",
       "factor(birthyear)1973 -0.21952    0.68051  -0.323  0.74713    \n",
       "factor(birthyear)1974 -0.50528    0.81518  -0.620  0.53562    \n",
       "factor(birthyear)1975 -0.49579    0.92400  -0.537  0.59178    \n",
       "factor(birthyear)1976 -0.58728    1.07649  -0.546  0.58559    \n",
       "factor(birthyear)1977 -0.59873    1.18378  -0.506  0.61321    \n",
       "factor(birthyear)1978 -0.39291    1.33023  -0.295  0.76782    \n",
       "factor(birthyear)1979 -0.19785    1.45787  -0.136  0.89210    \n",
       "factor(birthyear)1980 -0.05931    1.66812  -0.036  0.97165    \n",
       "factor(birthyear)1981  0.20851    1.76891   0.118  0.90621    \n",
       "factor(birthyear)1982 -0.41444    1.92410  -0.215  0.82954    \n",
       "factor(birthyear)1983 -0.25486    2.07659  -0.123  0.90237    \n",
       "factor(birthyear)1984 -0.03302    2.21665  -0.015  0.98812    \n",
       "factor(birthyear)1985  0.12250    2.40184   0.051  0.95934    \n",
       "m_edu                  0.38694    0.03517  11.001  < 2e-16 ***\n",
       "black                 -0.53112    0.29855  -1.779  0.07579 .  \n",
       "age                    0.06998    0.15401   0.454  0.64973    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.849 on 562 degrees of freedom\n",
       "Multiple R-Squared: 0.2161,\tAdjusted R-squared: 0.1896 \n",
       "Wald test: 8.154 on 19 and 562 DF,  p-value: < 2.2e-16 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit.f = ivreg(edu ~ edu_dens + factor(birthyear) + m_edu + black + age, data=df.m)\n",
    "summary(fit.f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh dear, the instrument is (unsurprisingly really weak after using controls). So what's the takeaway? Our instrument is likely weak for two reasons: (1) our measure of \"distance to college\" is the same for everybody in the same state, so there is a lot of measurement error in this variable and this should weaken the first stage, (2) we use the number of colleges in states in year 2017, which may not accurately reflect the number of colleges in each individuals birth state, so as a proxy for distance to college, this variable is pretty bad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
